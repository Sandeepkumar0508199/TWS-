Hi TDR Team,
We have successfully set up the new TWS automated trigger for Master PL Two A to B pipeline. Since this is now working correctly, we need to discontinue the existing manual trigger process to avoid duplicate runs.
Please stop triggering PL Notify CCams - this will automatically stop the chain that triggers PL TDR Request and subsequently Master PL Two A to B.
Going forward, TWS will handle the pipeline triggering automatically after EBS job completion. Let me know once you've disabled the trigger from your end.
Thanks!

My Tasks for Current Phase
Pipeline Development:

Build the main data pipeline in Azure
Connect it to our trading data sources
Set up automatic data processing
Add error handling when things go wrong

Data Processing Setup:

Configure Databricks for fraud detection
Set up the analysis notebooks
Test the alert generation system

Database Configuration:

Verify our data tables are ready
Test stored procedures
Make sure alerts save properly

Security Implementation:

Set up secure connections
Manage passwords safely
Control who can access what

Testing & Validation:

Run tests to make sure everything works
Check data quality
Verify alerts trigger correctly

My Work for September Phase
Data Integration:

Add new trading data feeds
Handle overlapping data properly
Scale up for more volume

System Monitoring:

Set up performance monitoring
Track system health
Fine-tune alert settings

What I Need to Get Started:

Azure access permissions
Database connections
Security approvals

Just checking — since the EBS job has already run today and was marked as successful (even though it failed in ADF), can TWS run it again today to test the updated failure scenario? Or will it skip re-running because the job already triggered once?
Hi [TDR Team / Name],

Quick question regarding the EBS job behavior:

What happens if there is no file received from upstream? Does the EBS job fail, show as completed, or stay in progress?

If a file is received but it has no data (empty file), will the EBS job still show as successful, and will it still trigger the analytics pipeline?

Just trying to understand how the job behaves in these scenarios for proper handling on our side. Let me know when you get a chance. Thanks!

How often does the EBS file get delayed?

Is it a frequent issue or only occasional?

By what time is the file typically received?

If the file is delayed and processed later in the day:

Will the TDR team inform us once it’s successfully processed?

Should we plan to manually rerun only the impacted T-1 analytics jobs (e.g., spoofing) afterward?

Does this approach sound reasonable to you?

If the EBS job hasn’t completed by 10:00 AM, we’ll go ahead and trigger the analytics pipeline manually.

Later, we’ll rerun only the impacted T-1 pipelines once the file is received and processed.

Let us know your thoughts. Thanks again!

Here’s the same thing in a simpler, plain form you can just share or say:

---

**Update:**
I have added a new step in the **If Condition → False** branch so the pipeline will fail when the load count does not match the expected count.

* If the counts **match** → the True branch runs as before, triggering analytics and completing successfully.
* If the counts **do not match** → the False branch runs a SQL script:

  ```sql
  THROW 50000, 'TDR Load conditions not met - Pipeline terminated', 1;
  ```

  which forces the pipeline to fail.
* This change makes sure TWS will not trigger downstream jobs when conditions are not met.

**Next step:**
Add this same False branch failure step in TDR’s **`PL_notify_Ccams`** pipeline. The True branch in TDR remains the same.

**Testing:**

* I tested in Ccams by making the counts match (pipeline succeeded) and by making them different (pipeline failed). Both behaved as expected.

Linked Service:
The Script activity in the False branch is linked to LS_TDRSqlServer.
This is correct, because that’s the SQL Server connection where the THROW 50000… statement will run.

Failure Activity after Script:
Yes — there is a Fail activity (Fail1) immediately after the Script in the False branch.
This explicitly marks the pipeline run as Failed in ADF monitoring, in addition to the Script error.


Chitra needs the following info to add the failure notification in the PL_notify_Ccams pipeline:

Recipient email IDs – Who should get the failure alert.

Email subject line – Clear and short, e.g., "TDR Load Failure – Pipeline Not Triggered".

Pipeline name(s) – The exact pipeline name(s) to include in the notification.

Any specific message/body text – If we want a custom failure message besides the default.

Hi Chitra,

Thank you for taking the time to add the changes. We have reviewed the pipeline.
Could you please add a failure notification to the Teams channel?
Also, would it be possible to grant contributor access in REL s

Here’s the full rephrased sentence for you:

**"Hi Chitra, thank you for taking the time to make the changes. We have checked the pipeline — is it possible to add failure notifications to the Teams channel? Also, is it possible to grant contributor access in REL so we can create our own branch and test the pipeline for both success and failure scenarios?"**

